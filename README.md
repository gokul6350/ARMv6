# **ARMv8**
[![Hits](https://hits.sh/github.com/gokul6350/ARMv6.svg?style=for-the-badge&label=Views&extraCount=10)](https://hits.sh/github.com/gokul6350/ARMv6/)[![Hits](https://hits.sh/discord.gg/ufeAzBjvAp.svg?style=for-the-badge&label=Discord&color=5953ee)](https://hits.sh/discord.gg/ufeAzBjvAp/)

![t](https://02ip.ru/1ZEeC4.png)

### YOUTUBE VIDEO 
[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/qv3bFhHoA5s/0.jpg)](https://www.youtube.com/watch?v=YOUTUBE_VIDEO_ID_HERE)

### library Used

- **TTS:** Pvorca
- **Object Detection:** YOLOv8 by Ultralytics
- **Vision Annotation:** Roboflow
- **Speech to Text:** Wisper AI
- **LLM:** Google Gemini Pro
- **Microcontroller:** Arduino Uno
- **UI:** Gradio
- **2D Simulator:** Matplotlib
- **Code Language:** Python 3.10
- Hot word detect : Porcupine
- VAD: Cobra

If you have $$$ for GPUs (not recommended), then you can make it completely offline.

### LLM Part:

- You can fine-tune a Mistral 7B with your data.
  - **Model:** [Mistral-7B-v0.1](https://huggingface.co/mistralai/Mistral-7B-v0.1/discussions/133)
  - **Tutorial:** [Mistral-7B Tutorial](https://www.datacamp.com/tutorial/mistral-7b-tutorial)
- My model (LORA Adapter Model) (FLOP): [Loara Chat Arm](https://huggingface.co/gokul00060/loara-chat-arm/tree/main)

### Speech to Text:

- You can run the same Wisper model locally with minor changes.

### TTS:

- In the text-to-speech model, you can use Bark. I tried Bark for this project. In Bark, you can even clone your voice.
  - [Bark GitHub Repository](https://github.com/suno-ai/bark)
