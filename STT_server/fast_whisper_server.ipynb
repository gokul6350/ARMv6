{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15FGYusaCg2s",
        "outputId": "d614b51b-9c40-4aeb-a85d-2d87052efcf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.6\n",
            "Collecting faster-whisper\n",
            "  Downloading faster_whisper-1.0.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting av<13,>=11.0 (from faster-whisper)\n",
            "  Downloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctranslate2<5,>=4.0 (from faster-whisper)\n",
            "  Downloading ctranslate2-4.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (192.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.3/192.3 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.23.1)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper) (0.19.1)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.25.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.11.0)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Installing collected packages: humanfriendly, ctranslate2, av, coloredlogs, onnxruntime, faster-whisper\n",
            "Successfully installed av-12.0.0 coloredlogs-15.0.1 ctranslate2-4.3.0 faster-whisper-1.0.2 humanfriendly-10.0 onnxruntime-1.18.0\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m943.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.38.0,>=0.37.2 (from fastapi)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.11.0)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting httpx>=0.23.0 (from fastapi)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.1.4)\n",
            "Collecting python-multipart>=0.0.7 (from fastapi)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.2.1 (from fastapi)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting uvicorn[standard]>=0.12.0 (from fastapi)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi) (3.7)\n",
            "Collecting typer>=0.12.3 (from fastapi-cli>=0.0.2->fastapi)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.23.0->fastapi)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->fastapi) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.23.0->fastapi)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.18.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (8.1.7)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.12.0->fastapi) (6.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.12.0->fastapi)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.23.0->fastapi) (1.2.1)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi) (0.1.2)\n",
            "Installing collected packages: websockets, uvloop, ujson, shellingham, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, watchfiles, uvicorn, starlette, httpcore, email_validator, typer, httpx, fastapi-cli, fastapi\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.3 python-dotenv-1.0.1 python-multipart-0.0.9 shellingham-1.5.4 starlette-0.37.2 typer-0.12.3 ujson-5.10.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "!pip install faster-whisper\n",
        "!ngrok config add-authtoken <your token>\n",
        "!pip install fastapi\n",
        "!git clone https://gist.github.com/gokul6350/4793092d5943ea38879df861bcaecd09.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvMfWrxeiZea",
        "outputId": "116c1d42-5fa1-4cee-8677-3ce9798c1687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using port: 5000\n",
            " * ngrok tunnel https://9f80-34-27-36-224.ngrok-free.app -> http://127.0.0.1:5000\n",
            "$$$$$$$$$$$$$$$$$$$$$$$$$\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [220]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "ERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 5000): address already in use\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FILE received: recorded_audio.wav\n",
            "TEXT received: battery,glue,lead,object_1\n",
            "FILE SAVED: 20240527131848_790160b20fdc4e3cb49e2058f12d9bdd.wav\n",
            "Audio loaded: 20240527131848_790160b20fdc4e3cb49e2058f12d9bdd.wav\n",
            "[0.00s -> 1.68s]  Pick up battery.\n",
            "you can see battery,glue,lead,object_1.  Pick up battery.\n",
            ">>>_pickup(battery) # picking up the battery\n",
            "INFO:     2405:201:e00a:7103:6a35:286:baae:3cd3:0 - \"POST /transcribe HTTP/1.1\" 200 OK\n",
            "FILE received: recorded_audio.wav\n",
            "TEXT received: battery,glue,lead,object_1\n",
            "FILE SAVED: 20240527131906_708cfc7e47e04585b584913e39618731.wav\n",
            "Audio loaded: 20240527131906_708cfc7e47e04585b584913e39618731.wav\n",
            "[0.00s -> 1.12s]  What are you doing boxing?\n",
            "you can see battery,glue,lead,object_1.  What are you doing boxing?\n",
            ">>>I am not boxing. I am picking up the battery.\n",
            "INFO:     2405:201:e00a:7103:6a35:286:baae:3cd3:0 - \"POST /transcribe HTTP/1.1\" 200 OK\n",
            "FILE received: recorded_audio.wav\n",
            "TEXT received: battery,glue,lead,object_1\n",
            "FILE SAVED: 20240527132259_3ad878df74c34415892e414ab37c4f12.wav\n",
            "Audio loaded: 20240527132259_3ad878df74c34415892e414ab37c4f12.wav\n",
            "[0.00s -> 1.74s]  Pick up battery.\n",
            "you can see battery,glue,lead,object_1.  Pick up battery.\n",
            ">>>_pickup(battery) # picking up the battery\n",
            "INFO:     2405:201:e00a:7103:6a35:286:baae:3cd3:0 - \"POST /transcribe HTTP/1.1\" 200 OK\n",
            "FILE received: recorded_audio.wav\n",
            "TEXT received: battery,glue,lead,object_1\n",
            "FILE SAVED: 20240527132325_d19c37c7cf074a6fb987872a12953cce.wav\n",
            "Audio loaded: 20240527132325_d19c37c7cf074a6fb987872a12953cce.wav\n",
            "[0.00s -> 1.88s]  Put it in box 1.\n",
            "you can see battery,glue,lead,object_1.  Put it in box 1.\n",
            ">>>_put(box1) # putting the object in box 1\n",
            "INFO:     2405:201:e00a:7103:6a35:286:baae:3cd3:0 - \"POST /transcribe HTTP/1.1\" 200 OK\n",
            "FILE received: recorded_audio.wav\n",
            "TEXT received: battery,glue,lead,object_1\n",
            "FILE SAVED: 20240527132343_22b914f8cce143fc9f554ecd34ef0075.wav\n",
            "Audio loaded: 20240527132343_22b914f8cce143fc9f554ecd34ef0075.wav\n",
            "[0.00s -> 1.80s]  Pick up object 1.\n",
            "you can see battery,glue,lead,object_1.  Pick up object 1.\n",
            ">>>_pickup(object_1) # picking up object 1\n",
            "INFO:     2405:201:e00a:7103:6a35:286:baae:3cd3:0 - \"POST /transcribe HTTP/1.1\" 200 OK\n",
            "FILE received: recorded_audio.wav\n",
            "TEXT received: battery,glue,lead,object_1\n",
            "FILE SAVED: 20240527132402_585fee1cbafa44ac9fdb8beb94002d45.wav\n",
            "Audio loaded: 20240527132402_585fee1cbafa44ac9fdb8beb94002d45.wav\n",
            "[0.00s -> 1.94s]  Put it in box 2.\n",
            "you can see battery,glue,lead,object_1.  Put it in box 2.\n",
            ">>>_put(box2) # putting the object in box 2\n",
            "INFO:     2405:201:e00a:7103:6a35:286:baae:3cd3:0 - \"POST /transcribe HTTP/1.1\" 200 OK\n",
            "FILE received: recorded_audio.wav\n",
            "TEXT received: battery,glue,lead,object_1\n",
            "FILE SAVED: 20240527132425_aca0d3eade564e0e9b5768b7c3bb3fba.wav\n",
            "Audio loaded: 20240527132425_aca0d3eade564e0e9b5768b7c3bb3fba.wav\n",
            "[0.05s -> 3.61s]  Pick up something which is used for sticking papers.\n",
            "you can see battery,glue,lead,object_1.  Pick up something which is used for sticking papers.\n",
            ">>>_pickup(glue) # picking up the glue\n",
            "INFO:     2405:201:e00a:7103:6a35:286:baae:3cd3:0 - \"POST /transcribe HTTP/1.1\" 200 OK\n",
            "FILE received: recorded_audio.wav\n",
            "TEXT received: battery,glue,lead,object_1\n",
            "FILE SAVED: 20240527132447_bed946de3e00460cb4ca679d53535528.wav\n",
            "Audio loaded: 20240527132447_bed946de3e00460cb4ca679d53535528.wav\n",
            "[0.00s -> 1.88s]  Put it in box 1.\n",
            "you can see battery,glue,lead,object_1.  Put it in box 1.\n",
            ">>>_put(box1) # putting the object in box 1\n",
            "INFO:     2405:201:e00a:7103:6a35:286:baae:3cd3:0 - \"POST /transcribe HTTP/1.1\" 200 OK\n",
            "FILE received: recorded_audio.wav\n",
            "TEXT received: battery,glue,lead,object_1\n",
            "FILE SAVED: 20240527132502_d25e24a8a4a84577b8fb1cdf21e705b2.wav\n",
            "Audio loaded: 20240527132502_d25e24a8a4a84577b8fb1cdf21e705b2.wav\n",
            "[0.00s -> 1.68s]  What is your name?\n",
            "you can see battery,glue,lead,object_1.  What is your name?\n",
            ">>>My name is jarvis. I am a  AI Robotic Arm Assistant.\n",
            "INFO:     2405:201:e00a:7103:6a35:286:baae:3cd3:0 - \"POST /transcribe HTTP/1.1\" 200 OK\n",
            "FILE received: recorded_audio.wav\n",
            "TEXT received: battery,glue,lead,object_1\n",
            "FILE SAVED: 20240527132627_caa2349e63f04c7dbf064f1d35a6fe8e.wav\n",
            "Audio loaded: 20240527132627_caa2349e63f04c7dbf064f1d35a6fe8e.wav\n",
            "[0.00s -> 1.08s]  Thank you.\n",
            "you can see battery,glue,lead,object_1.  Thank you.\n",
            ">>>You are welcome!\n",
            "INFO:     2405:201:e00a:7103:6a35:286:baae:3cd3:0 - \"POST /transcribe HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import threading\n",
        "from fastapi import FastAPI, File, UploadFile, HTTPException ,Form\n",
        "from fastapi.responses import JSONResponse\n",
        "from pyngrok import ngrok\n",
        "from faster_whisper import WhisperModel\n",
        "import google.generativeai as genai\n",
        "import psutil\n",
        "from datetime import datetime\n",
        "import uuid\n",
        "import uvicorn\n",
        "\n",
        "model_size = \"large-v3\"\n",
        "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
        "app = FastAPI()\n",
        "port = \"5000\"\n",
        "\n",
        "generation_config = {\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 0,\n",
        "    \"max_output_tokens\": 8192,\n",
        "}\n",
        "\n",
        "safety_settings = []\n",
        "\n",
        "model1 = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                               generation_config=generation_config,\n",
        "                               safety_settings=safety_settings)\n",
        "\n",
        "def gen_ai(prompt):\n",
        "\n",
        "    with open('4793092d5943ea38879df861bcaecd09/prompt.txt', 'r') as file:\n",
        "      content = file.read().splitlines()\n",
        "\n",
        "\n",
        "    frompt_parts = [line.format(prompt=prompt).strip() for line in content]\n",
        "\n",
        "\n",
        "    response = model1.generate_content(frompt_parts)\n",
        "    print(f\">>>{response.text}\")\n",
        "\n",
        "    return response.text\n",
        "\n",
        "def is_port_in_use(port):\n",
        "    for proc in psutil.process_iter():\n",
        "        try:\n",
        "            pinfo = proc.as_dict(attrs=['pid', 'name', 'cmdline'])\n",
        "            if 'python' in pinfo['name'] and 'uvicorn' in ' '.join(pinfo['cmdline']) and port in ' '.join(pinfo['cmdline']):\n",
        "                return True\n",
        "        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n",
        "            pass\n",
        "    return False\n",
        "\n",
        "def find_available_port(start_port):\n",
        "    port = start_port\n",
        "    while is_port_in_use(str(port)):\n",
        "        port += 1\n",
        "    return port\n",
        "\n",
        "def stop_existing_uvicorn_server(port):\n",
        "    for proc in psutil.process_iter():\n",
        "        try:\n",
        "            pinfo = proc.as_dict(attrs=['pid', 'name', 'cmdline'])\n",
        "            if 'python' in pinfo['name'] and 'uvicorn' in ' '.join(pinfo['cmdline']) and port in ' '.join(pinfo['cmdline']):\n",
        "                print(f\"Stopping existing Uvicorn server (PID: {pinfo['pid']})...\")\n",
        "                proc.terminate()\n",
        "        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n",
        "            pass\n",
        "\n",
        "stop_existing_uvicorn_server(port)\n",
        "new_port = find_available_port(int(port))\n",
        "print(f\"Using port: {new_port}\")\n",
        "\n",
        "public_url = ngrok.connect(new_port).public_url\n",
        "print(f\" * ngrok tunnel {public_url} -> http://127.0.0.1:{new_port}\")\n",
        "app.state.base_url = public_url\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def index():\n",
        "    return {\"message\": \"Hello from Colab!\"}\n",
        "\n",
        "def generate_unique_filename():\n",
        "    unique_id = uuid.uuid4().hex\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "    return f\"{timestamp}_{unique_id}.wav\"\n",
        "\n",
        "@app.post(\"/transcribe\")\n",
        "async def transcribe_audio(file: UploadFile = File(...), text: str = Form(...)):\n",
        "    if not file:\n",
        "        raise HTTPException(status_code=400, detail=\"No file part\")\n",
        "    if file.filename == '':\n",
        "        raise HTTPException(status_code=400, detail=\"No selected file\")\n",
        "\n",
        "    print(f\"FILE received: {file.filename}\")\n",
        "    print(f\"TEXT received: {text}\")\n",
        "\n",
        "    unique_filename = generate_unique_filename()\n",
        "    file_path = f\"/content/{unique_filename}\"\n",
        "\n",
        "    with open(file_path, \"wb\") as buffer:\n",
        "        buffer.write(file.file.read())\n",
        "\n",
        "    print(f\"FILE SAVED: {unique_filename}\")\n",
        "\n",
        "    segments, info = model.transcribe(file_path, beam_size=5, vad_filter=True, vad_parameters=dict(min_silence_duration_ms=500))\n",
        "\n",
        "    print(f\"Audio loaded: {unique_filename}\")\n",
        "\n",
        "    for segment in segments:\n",
        "        print(f\"[{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}\")\n",
        "    promt=f\"you can see {text}. {segment.text}\"\n",
        "    print(promt)\n",
        "    rep = gen_ai(promt)\n",
        "    return JSONResponse(content={'reply': rep, 'text': segment.text, 'Request_ID': unique_filename})\n",
        "\n",
        "def start_uvicorn():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=new_port, log_level=\"info\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    thread = threading.Thread(target=start_uvicorn, daemon=True)\n",
        "    thread.start()\n",
        "\n",
        "    print(\"$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
        "    input(\"Press Enter to stop the server...\")\n",
        "\n",
        "    os._exit(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8a-_iTI15HZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82WiHXhHFPtp"
      },
      "source": [
        "### TESTING LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tpi4z2zA7BB",
        "outputId": "7b4893be-e745-4c58-afe2-1acdedd0d07c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are authorizing client libraries without access to a web browser. Please run the following command on a machine with a web browser and copy its output back here. Make sure the installed gcloud version is 372.0.0 or newer.\n",
            "\n",
            "gcloud auth application-default login --remote-bootstrap=\"https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=831752801621-nc9rdedhutk7btnb33cvqohsh3rrglmm.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgenerative-language.tuning+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgenerative-language.retriever&state=ZoCkGVb9DtUGGbbd0ryStl3GPUuKPS&access_type=offline&code_challenge=txy2ypIb1lVHQAcehy6smyazajju7djOaAAQVyOnbXQ&code_challenge_method=S256&token_usage=remote\"\n",
            "\n",
            "\n",
            "Enter the output of the above command: https://localhost:8085/?state=ZoCkGVb9DtUGGbbd0ryStl3GPUuKPS&code=4/0AdLIrYcOhi8_8U4VvZMez1L3xlVvriFI7LpiDmLgH0I4JPlGLCWmZXkLVqBj7W8iqTb-DA&scope=https://www.googleapis.com/auth/cloud-platform%20https://www.googleapis.com/auth/generative-language.retriever%20https://www.googleapis.com/auth/generative-language.tuning\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n"
          ]
        }
      ],
      "source": [
        "!gcloud auth application-default login \\\n",
        "  --no-browser --client-id-file /content/client_secret.json \\\n",
        "  --scopes https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/generative-language.tuning,https://www.googleapis.com/auth/generative-language.retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZJGpeU-b4XI",
        "outputId": "e1786c67-cc5d-41be-c035-e6a787d29ce2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>>_hello\n",
            "_hello\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import google.generativeai as genai\n",
        "generation_config = {\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 0,\n",
        "    \"max_output_tokens\": 8192,\n",
        "}\n",
        "\n",
        "safety_settings = []\n",
        "\n",
        "model1 = genai.GenerativeModel(model_name=\"tunedModels/dataset-reb3qi4cuvqu\",\n",
        "                               generation_config=generation_config,\n",
        "                               safety_settings=safety_settings)\n",
        "\n",
        "\n",
        "def gen_ai(prompt):\n",
        "\n",
        "    with open('4793092d5943ea38879df861bcaecd09/prompt.txt', 'r') as file:\n",
        "      content = file.read().splitlines()\n",
        "\n",
        "\n",
        "    frompt_parts = [line.format(prompt=prompt).strip() for line in content]\n",
        "\n",
        "\n",
        "    response = model1.generate_content(frompt_parts)\n",
        "    print(f\">>>{response.text}\")\n",
        "\n",
        "    return response.text\n",
        "print(gen_ai(\"hello\"))\n",
        "print(gen_ai(\"whats you name ?\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}